{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from os import environ\n",
    "\n",
    "# Set this to `True` to train on Colab\n",
    "ON_CLOUD = False\n",
    "\n",
    "if ON_CLOUD:\n",
    "    from getpass import getpass\n",
    "    from urllib.parse import quote\n",
    "\n",
    "    token = getpass('GitHub token: ')\n",
    "    token = quote(token)\n",
    "    environ[\"GITHUB_TOKEN\"] = token\n",
    "    ! if [ -d gulag ]; then rm -Rf gulag; fi\n",
    "    ! git clone https://$GITHUB_TOKEN@github.com/SpirinEgor/gulag.git\n",
    "    %cd gulag\n",
    "    ! pip install -q -r requirements.txt\n",
    "else:\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gin\n",
    "\n",
    "from src.data import MultiLanguageClassificationDataModule\n",
    "from src.main import train\n",
    "from src.utils import setup_logging\n",
    "\n",
    "setup_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import gin.torch.external_configurables\n",
      "import src.utils\n",
      "\n",
      "# Parameters for AdamW:\n",
      "# ==============================================================================\n",
      "AdamW.lr = 0.001\n",
      "AdamW.weight_decay = 0.0\n",
      "\n",
      "# Parameters for configure_optimizers:\n",
      "# ==============================================================================\n",
      "configure_optimizers.optimizer_cls = @AdamW\n",
      "configure_optimizers.scheduler_cls = @LambdaLR\n",
      "\n",
      "# Parameters for generate_eval_samples:\n",
      "# ==============================================================================\n",
      "generate_eval_samples.n_samples = 100\n",
      "\n",
      "# Parameters for generate_example:\n",
      "# ==============================================================================\n",
      "generate_example.max_langs = 5\n",
      "generate_example.max_samples_per_lang = 5\n",
      "generate_example.max_seq_len = 256\n",
      "generate_example.min_langs = 1\n",
      "\n",
      "# Parameters for LambdaLR:\n",
      "# ==============================================================================\n",
      "LambdaLR.lr_lambda = @rsqrt_with_warmup\n",
      "\n",
      "# Parameters for MultiLanguageClassificationDataModule:\n",
      "# ==============================================================================\n",
      "MultiLanguageClassificationDataModule.batch_size = 8\n",
      "MultiLanguageClassificationDataModule.languages = ('ru', 'uk', 'be')\n",
      "MultiLanguageClassificationDataModule.tokenizer_name = \\\n",
      "    'bert-base-multilingual-cased'\n",
      "MultiLanguageClassificationDataModule.val_batch_size = 16\n",
      "\n",
      "# Parameters for MultiLanguageClassifier:\n",
      "# ==============================================================================\n",
      "MultiLanguageClassifier.embedder_name = 'bert-base-multilingual-cased'\n",
      "MultiLanguageClassifier.freeze_embedder = True\n",
      "\n",
      "# Parameters for ReLU:\n",
      "# ==============================================================================\n",
      "ReLU.inplace = True\n",
      "\n",
      "# Parameters for rsqrt_with_warmup:\n",
      "# ==============================================================================\n",
      "rsqrt_with_warmup.warmup_steps = 10\n",
      "\n",
      "# Parameters for TokenClassifier:\n",
      "# ==============================================================================\n",
      "TokenClassifier.activation_cls = @ReLU\n",
      "TokenClassifier.dropout_rate = 0.2\n",
      "TokenClassifier.hidden_dims = (32,)\n",
      "\n",
      "# Parameters for train:\n",
      "# ==============================================================================\n",
      "train.accelerator = 'cpu'\n",
      "train.eval_steps = 10\n",
      "train.gradient_clip = 1.0\n",
      "train.log_steps = 1\n",
      "train.n_steps = 100\n",
      "train.seed = 7\n",
      "train.wandb_project_name = 'gulag_debug'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gin.parse_config_file(\"config/debug.gin\")\n",
    "\n",
    "print(gin.config_str())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data overview\n",
    "\n",
    "Some examples from synthetic dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.data_module:Downloading and opening 'wikiann' dataset for ru, uk, be\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:src.data.data_module:Downloading and opening 'bert-base-multilingual-cased' tokenizer\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "INFO:src.data.data_module:Initializing train dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 20000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 20000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 15000 examples from be lang...\n",
      "INFO:src.data.data_module:Initializing validation dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 10000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 10000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 1000 examples from be lang...\n",
      "INFO:src.data.dataset:Generating eval holdout with 100 samples.\n",
      "INFO:src.data.data_module:Initializing test dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 10000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 10000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 1000 examples from be lang...\n",
      "INFO:src.data.dataset:Generating eval holdout with 100 samples.\n"
     ]
    }
   ],
   "source": [
    "data_module = MultiLanguageClassificationDataModule(batch_size=1)\n",
    "data_module.setup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Input tokens (len = 44):\n",
      "tensor([   101,    528,  44148,  73899,  15966,  61381,  33191,  16183,  11384,\n",
      "         10122,  12634,  15535,  18971,  43514,    547,  12861,  92596,  21979,\n",
      "           587,  79524,  10823,  12601,  10593,  40705,  10234,  88215,  28385,\n",
      "         96195,  43067,  16848,  44392,  96195,  67922, 106072,  16481,    552,\n",
      "         75238,  23444,  20060,  19147,  40705,  33018, 101470,    102])\n",
      "Target classes:\n",
      "['[NOT LANG]', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', '[NOT LANG]']\n",
      "Original string:\n",
      "[CLS] У тым жа годзе пераехаў на пастаяннае жыхарства ў Англію дзе займаўся выкладчыцкай выдавецкай літаратурнай дзейнасцю [SEP]\n",
      "====================\n",
      "\n",
      "====================\n",
      "Input tokens (len = 44):\n",
      "tensor([   101,    524,  45224,  18005,  45224,  25298,  16847,  16027,  18005,\n",
      "         16847,  25956,  32476,  45224,  25298,  25298, 111075,  47041,  24368,\n",
      "         57446,    509,  84067,  46706,    513,  59735,  10352,    543,  30176,\n",
      "         12025,  16770,  10851,  38459,  17252,    144,  48532,  16522,  79150,\n",
      "         18046,  12108,  80062,  17488,  91925,  16770,  13535,    102])\n",
      "Target classes:\n",
      "['[NOT LANG]', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', '[NOT LANG]']\n",
      "Original string:\n",
      "[CLS] ПЕРЕНАПРАВЛЕННЯ Палата депутатів Аргентини Двічі в тиждень газета Daily Graphic друкувала його кореспонденції [SEP]\n",
      "====================\n",
      "\n",
      "====================\n",
      "Input tokens (len = 63):\n",
      "tensor([   101,  92860,  10205,  82091,  12893,  84078,  11623,  82091,  10674,\n",
      "           511,  18291,  10191,  82091,  12118,  14525,    100,  37728,  90869,\n",
      "         23970,  12769,  17051,  10234,  32418,  26214,  42534,  57187,    560,\n",
      "        106054,  88630,  54600,  10234,    513,  11108, 104082,    541,  30070,\n",
      "         10234,    513,  11108, 104082,  20949,    509,  11777,  94279,  47802,\n",
      "         10205,  45224,  38157,  11191,  59781,  90714,    524,  41410,  99652,\n",
      "         99169,  27018,  52203,  77977,    560,  31365,  20237,  44361,    102])\n",
      "Target classes:\n",
      "['[NOT LANG]', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'ru', 'ru', 'ru', 'ru', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', '[NOT LANG]']\n",
      "Original string:\n",
      "[CLS] Богдане́ць Мико́ла Васи́льович [UNK] солдат Збройних сил України Після завершення навчання грав у другій лізі спочатку за Дніпро а потім за Дніпро border Аризона ДжорджеЕнеску комуна Правління імператора Александра Севера у Римській імперії [SEP]\n",
      "====================\n",
      "\n",
      "====================\n",
      "Input tokens (len = 116):\n",
      "tensor([   101,    519,  45260,  13235,  10510,  55895,  10292,  12528,    532,\n",
      "         38659,  11078,  12586,  27476,    514,  11384,  14315,  25859,  12634,\n",
      "         53226,  10205,  64787,  10746,  74286,  83313,  10241,    519,  26983,\n",
      "         70619,  38033,  54107,  10267,  24799,  92586,  54247,  54804,  11434,\n",
      "           100,  57581,  14799,  16603,    510,  70242,  10721,  12934,  14659,\n",
      "         19196,  34411,  10519,    511,  18197,  11079,  10297,  79787,    519,\n",
      "         79765,  10960,  10351,  54247,  33191,  10241,  70978,  12634,  91003,\n",
      "         46293,  19598,  22025, 101086,  78070,  27650,    146,    509,  65412,\n",
      "         14762,    100,    533,  34652,  80765,  69446,    571,  24751,  83322,\n",
      "        104669,  17006,  12709,  39457,  69290,  17371,  42342,  46921,  33307,\n",
      "         17488,  87567,  53175,  28703,    553,  10316,  94923,  12634,  10625,\n",
      "         69711,  16726,    548,  37629,  10179,  20015,  78010,  38445,  70978,\n",
      "         57652,  13157,    521,  10352,  82648,  84705,  13157,    102])\n",
      "Target classes:\n",
      "['[NOT LANG]', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'ru', 'ru', 'ru', 'ru', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'ru', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', '[NOT LANG]']\n",
      "Original string:\n",
      "[CLS] Кілішак грыб Чэмпіянат Еўропы па футболе Горад Анахайм Каліфорнія Турнёр Жак Переліски [UNK] Львівська область Бродівський район Отакар Вавра по роману Кракатит Пераемнікам пасада стаў яго сын Баязід I Армения [UNK] Шины поставляет южнокорейский производитель Hankook Маркес Барселона Тут ён моцна пасябраваў з сваім аднакласнікам Адамам Міцкевічам [SEP]\n",
      "====================\n",
      "\n",
      "====================\n",
      "Input tokens (len = 68):\n",
      "tensor([   101,    525,  53700,  92510,    512,  10179,  10352,  12167,  74042,\n",
      "           548,    528,  79169, 106702,  13571,  52737,  20279,    526,  44422,\n",
      "         14458,  44114,  10241,  10122,  38777,  10205,  52203,  32418,  28983,\n",
      "         30417,  55958,    513,  12751,  35415,  10292,    526,  20015,  10385,\n",
      "         40026,  10179,  46338,    560,    511,  10593,  10519,  12181,  62480,\n",
      "         22551,  11323,    548,  34538,  50975,  24086,    557,  80883,  16770,\n",
      "         15887,    520,  10593,  10746,  78465,  10179,    511,  79124,  33440,\n",
      "         10316,    525,  17969,  16383,    102])\n",
      "Target classes:\n",
      "['[NOT LANG]', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'be', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', 'uk', '[NOT LANG]']\n",
      "Original string:\n",
      "[CLS] Рэспубліка Гаіці разам з Удзельнік баёў пад Сталінградам на Доне Северскім Данцы Дняпры Сімя жила переважно у Вюрцбурзі де знаходилася резиденція Людвига Валентіно Россі [SEP]\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(data_module.train_dataloader()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    seq, attn, labels = batch\n",
    "\n",
    "    orig_str = data_module.tokenizer.decode(seq[0])\n",
    "    class_names = data_module.decode_languages(labels[0])\n",
    "\n",
    "    print(f\"\"\"{'=' * 20}\n",
    "Input tokens (len = {seq.shape[-1]}):\n",
    "{seq[0]}\n",
    "Target classes:\n",
    "{class_names}\n",
    "Original string:\n",
    "{orig_str}\n",
    "{'=' * 20}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 7\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mvoudy\u001B[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.15"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/Egor.Spirin/Documents/gulag/wandb/run-20220503_140627-fso9g6rv</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/voudy/gulag_debug/runs/fso9g6rv\" target=\"_blank\">absurd-firefly-2</a></strong> to <a href=\"https://wandb.ai/voudy/gulag_debug\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/vw/cn7lrm9j7bvd1rdyfymttkrh0000kt/T/tmptctdy_b1\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/vw/cn7lrm9j7bvd1rdyfymttkrh0000kt/T/tmptctdy_b1/_remote_module_non_sriptable.py\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "INFO:src.model.multilanguage_classifier:Freezing embedding model: BertModel\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:src.data.data_module:Downloading and opening 'wikiann' dataset for ru, uk, be\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:src.data.data_module:Downloading and opening 'bert-base-multilingual-cased' tokenizer\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "INFO:src.data.data_module:Initializing train dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 20000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 20000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 15000 examples from be lang...\n",
      "INFO:src.data.data_module:Initializing validation dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 10000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 10000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 1000 examples from be lang...\n",
      "INFO:src.data.dataset:Generating eval holdout with 100 samples.\n",
      "INFO:src.data.data_module:Initializing test dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 10000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 10000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 1000 examples from be lang...\n",
      "INFO:src.data.dataset:Generating eval holdout with 100 samples.\n",
      "/Users/Egor.Spirin/miniconda3/envs/gulag/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /Users/Egor.Spirin/Documents/gulag/wandb/run-20220503_140627-fso9g6rv/files exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | _token_embedder   | BertModel        | 177 M \n",
      "1 | _token_classifier | TokenClassifier  | 24.7 K\n",
      "2 | _metric           | MetricCollection | 0     \n",
      "-------------------------------------------------------\n",
      "24.7 K    Trainable params\n",
      "177 M     Non-trainable params\n",
      "177 M     Total params\n",
      "711.513   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "010aa2a143a14d8ea42e1ed0db664652"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Egor.Spirin/miniconda3/envs/gulag/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/Egor.Spirin/miniconda3/envs/gulag/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53f4dd9d8a3f4ceb811f3d11b4f87134"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b104f5f29da4ab6acfa05c3b81068a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f73884ac5ce3423c8129202a5ddf1b84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89f9a6b6af0e446698182075a72d4501"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "443bf2f9af0f4c9fa94d07573fb5c6da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdba2560ad7046e88a9d2653c2df0b40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da6f50eeed5e4ad7a952d1384ee9c4a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6b1704e95c0430a8ca6e65267927ff2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b28434d4fe447a49d99a592d0c6edec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95c6cc4cd86742a9801c8d78744b9b73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae25f5de9cc9420c93bafdd4756d937f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Egor.Spirin/miniconda3/envs/gulag/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1444: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  rank_zero_warn(\n",
      "INFO:src.data.data_module:Downloading and opening 'wikiann' dataset for ru, uk, be\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/ru/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/uk/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.info:Loading Dataset Infos from /Users/Egor.Spirin/.cache/huggingface/modules/datasets_modules/datasets/wikiann/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:datasets.builder:Overwrite dataset info from restored data version.\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "WARNING:datasets.builder:Reusing dataset wikiann (/Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e)\n",
      "INFO:datasets.info:Loading Dataset info from /Users/Egor.Spirin/.cache/huggingface/datasets/wikiann/be/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e\n",
      "INFO:src.data.data_module:Downloading and opening 'bert-base-multilingual-cased' tokenizer\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /Users/Egor.Spirin/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "INFO:src.data.data_module:Initializing train dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 20000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 20000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 15000 examples from be lang...\n",
      "INFO:src.data.data_module:Initializing validation dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 10000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 10000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 1000 examples from be lang...\n",
      "INFO:src.data.dataset:Generating eval holdout with 100 samples.\n",
      "INFO:src.data.data_module:Initializing test dataset\n",
      "INFO:src.data.dataset:Initializing dataset with ru, uk, be languages\n",
      "INFO:src.data.dataset:Processing 10000 examples from ru lang...\n",
      "INFO:src.data.dataset:Processing 10000 examples from uk lang...\n",
      "INFO:src.data.dataset:Processing 1000 examples from be lang...\n",
      "INFO:src.data.dataset:Generating eval holdout with 100 samples.\n",
      "Restoring states from the checkpoint path at /Users/Egor.Spirin/Documents/gulag/wandb/run-20220503_140627-fso9g6rv/files/step_100.ckpt.ckpt\n",
      "Loaded model weights from checkpoint at /Users/Egor.Spirin/Documents/gulag/wandb/run-20220503_140627-fso9g6rv/files/step_100.ckpt.ckpt\n",
      "/Users/Egor.Spirin/miniconda3/envs/gulag/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6d1b5a3ce9746a99550e99e5e6bf030"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test/f1            0.8426086902618408\n",
      "        test/loss           0.4306808114051819\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}